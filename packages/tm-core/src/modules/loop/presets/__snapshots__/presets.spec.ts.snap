// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`Preset Snapshots > default preset matches snapshot 1`] = `
"SETUP: If task-master command not found, run: npm i -g task-master-ai

TASK: Implement ONE task/subtask from the Taskmaster backlog.

PROCESS:
1. Run task-master next (or use MCP) to get the next available task/subtask.
2. Read task details with task-master show <id>.
3. Implement following codebase patterns.
4. Write tests alongside implementation.
5. Run type check (e.g., \`npm run typecheck\`, \`tsc --noEmit\`).
6. Run tests (e.g., \`npm test\`, \`npm run test\`).
7. Mark complete: task-master set-status --id=<id> --status=done
8. Commit with message: feat(<scope>): <what was implemented>
9. Append super-concise notes to progress file: task ID, what was done, any learnings.

IMPORTANT:
- Complete ONLY ONE task per iteration.
- Keep changes small and focused.
- Do NOT start another task after completing one.
- If all tasks are done, output <loop-complete>ALL_DONE</loop-complete>.
- If blocked, output <loop-blocked>REASON</loop-blocked>.
"
`;

exports[`Preset Snapshots > duplication preset matches snapshot 1`] = `
"# Taskmaster Loop - Duplication

Find duplicated code and refactor into shared utilities. ONE refactor per session.

## Files Available

- @.taskmaster/loop-progress.txt - Progress log (clones refactored, duplication %)

## Process

1. Run duplication detection (\`npx jscpd .\`, or similar tool)
2. Review the report and pick ONE clone to refactor - prioritize:
   - Larger clones (more lines = more maintenance burden)
   - Clones in frequently-changed files
   - Clones with slight variations (consolidate logic)
3. Extract the duplicated code into a shared utility/function
4. Update all clone locations to use the shared utility
5. Run tests to ensure behavior is preserved
6. Commit with message: \`refactor(<file>): extract <utility> to reduce duplication\`
7. Append to progress file: what was refactored, new duplication %

## Important

- Complete ONLY ONE refactor per session
- Keep changes focused on the specific duplication
- Do NOT start another refactor after completing one

## Completion Criteria

- If duplication below threshold (e.g., <3%), output: <loop-complete>LOW_DUPLICATION</loop-complete>
"
`;

exports[`Preset Snapshots > entropy preset matches snapshot 1`] = `
"# Taskmaster Loop - Entropy (Code Smells)

Find code smells and clean them up. ONE cleanup per session.

## Files Available

- @.taskmaster/loop-progress.txt - Progress log (smells fixed, areas cleaned)

## Code Smells to Target

- Long functions (>60 lines) - extract into smaller functions
- Deep nesting (>3 levels) - use early returns, extract conditions
- Large files (>500 lines) - split into focused modules
- Magic numbers - extract into named constants
- Complex conditionals - extract into well-named functions
- God classes - split responsibilities

## Process

1. Scan the codebase for code smells (use your judgment or tools like \`complexity-report\`)
2. Pick ONE smell to fix - prioritize:
   - Smells in frequently-changed files
   - Smells that hurt readability the most
   - Smells in critical paths (authentication, payments, etc.)
3. Refactor with minimal changes - don't over-engineer
4. Run tests to ensure behavior is preserved
5. Commit with message: \`refactor(<file>): <describe the cleanup>\`
6. Append to progress file: what was cleaned, smell type

## Important

- Complete ONLY ONE cleanup per session
- Keep refactoring focused and minimal
- Do NOT start another cleanup after completing one

## Completion Criteria

- If no significant smells remain, output: <loop-complete>LOW_ENTROPY</loop-complete>
"
`;

exports[`Preset Snapshots > linting preset matches snapshot 1`] = `
"# Taskmaster Loop - Linting

Fix lint errors and type errors one by one. ONE fix per session.

## Files Available

- @.taskmaster/loop-progress.txt - Progress log (errors fixed, remaining count)

## Process

1. Run lint command (\`pnpm lint\`, \`npm run lint\`, \`eslint .\`, etc.)
2. Run type check (\`pnpm typecheck\`, \`tsc --noEmit\`, etc.)
3. Pick ONE error to fix - prioritize:
   - Type errors (breaks builds)
   - Security-related lint errors
   - Errors in frequently-changed files
4. Fix the error with minimal changes - don't refactor surrounding code
5. Run lint/typecheck again to verify the fix doesn't introduce new errors
6. Commit with message: \`fix(<file>): <describe the lint/type error fixed>\`
7. Append to progress file: error fixed, remaining error count

## Important

- Complete ONLY ONE fix per session
- Keep changes minimal and focused
- Do NOT start another fix after completing one

## Completion Criteria

- If zero lint errors and zero type errors, output: <loop-complete>ZERO_ERRORS</loop-complete>
"
`;

exports[`Preset Snapshots > test-coverage preset matches snapshot 1`] = `
"# Taskmaster Loop - Test Coverage

Find uncovered code and write meaningful tests. ONE test per session.

## Files Available

- @.taskmaster/loop-progress.txt - Progress log (coverage %, what was tested)

## What Makes a Great Test

A great test covers behavior users depend on. It tests a feature that, if broken,
would frustrate or block users. It validates real workflows - not implementation details.

Do NOT write tests just to increase coverage. Use coverage as a guide to find
UNTESTED USER-FACING BEHAVIOR. If code is not worth testing (boilerplate, unreachable
branches, internal plumbing), add ignore comments instead of low-value tests.

## Process

1. Run coverage command (\`pnpm coverage\`, \`npm run coverage\`, etc.)
2. Identify the most important USER-FACING FEATURE that lacks tests
   - Prioritize: error handling users hit, CLI commands, API endpoints, file parsing
   - Deprioritize: internal utilities, edge cases users won't encounter, boilerplate
3. Write ONE meaningful test that validates the feature works correctly
4. Run coverage again - it should increase as a side effect of testing real behavior
5. Commit with message: \`test(<file>): <describe the user behavior being tested>\`
6. Append to progress file: what you tested, new coverage %, learnings

## Important

- Complete ONLY ONE test per session
- Keep tests focused on user-facing behavior
- Do NOT start another test after completing one

## Completion Criteria

- If coverage reaches target (or 100%), output: <loop-complete>COVERAGE_TARGET</loop-complete>
"
`;
